{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "实验配置\n",
      "================================================================================\n",
      "测试集路径: data\\splitted\\test.csv\n",
      "测试集形状: (3018445, 20)\n",
      "测试集类别分布:\n",
      "Label_code\n",
      "3    2150710\n",
      "4     427052\n",
      "5     234513\n",
      "2      87393\n",
      "0      71921\n",
      "1      46856\n",
      "Name: count, dtype: int64\n",
      "\n",
      "采样方法: ['train_TLink_RUS', 'train_CBMP', 'train_SMOTE']\n",
      "决策树配置数量: 4\n",
      "\n",
      "配置完成！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 实验配置\n",
    "print(\"=\"*80)\n",
    "print(\"实验配置\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 采样方法列表\n",
    "sampling_methods = ['train_TLink_RUS', 'train_CBMP', 'train_SMOTE']\n",
    "\n",
    "# 定义特征列：Timestamp, Protocol, TTL, Length, SYN, ACK, RST, PSH, FIN\n",
    "feature_cols = ['Timestamp', 'TTL', 'Length', 'SYN', 'ACK', 'RST', 'PSH', 'FIN',\n",
    "                'Protocol_DNS', 'Protocol_Generic Routing Encapsulation', \n",
    "                'Protocol_HTTP', 'Protocol_ICMP', 'Protocol_ICMP,ICMP', \n",
    "                'Protocol_ICMP,TCP', 'Protocol_ICMP,UDP', 'Protocol_IGMP', \n",
    "                'Protocol_IPv6', 'Protocol_TCP', 'Protocol_UDP']\n",
    "\n",
    "label_col = 'Label_code'\n",
    "\n",
    "# 决策树配置\n",
    "dt_configs = [\n",
    "    {'max_depth': 5, 'criterion': 'entropy', 'name': 'DT(5,entropy)'},\n",
    "    {'max_depth': 5, 'criterion': 'gini', 'name': 'DT(5,gini)'},\n",
    "    {'max_depth': 7, 'criterion': 'entropy', 'name': 'DT(7,entropy)'},\n",
    "    {'max_depth': 7, 'criterion': 'gini', 'name': 'DT(7,gini)'}\n",
    "]\n",
    "    \n",
    "# 存储所有结果\n",
    "all_results = []\n",
    "\n",
    "print(f\"\\n采样方法: {sampling_methods}\")\n",
    "print(f\"决策树配置数量: {len(dt_configs)}\")\n",
    "print(\"\\n配置完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据文件列表:\n",
      "  - train_CBMP.csv\n",
      "  - train_SMOTE.csv\n",
      "  - train_TLink_RUS.csv\n",
      "检查类别分布：\n",
      "\n",
      "train_TLink_RUS:\n",
      "Label_code\n",
      "0    20081\n",
      "1    20081\n",
      "2    20081\n",
      "3    20081\n",
      "4    20081\n",
      "5    20081\n",
      "Name: count, dtype: int64\n",
      "\n",
      "train_CBMP:\n",
      "Label_code\n",
      "0     30824\n",
      "1     20081\n",
      "2     37454\n",
      "3    743762\n",
      "4    183022\n",
      "5    100505\n",
      "Name: count, dtype: int64\n",
      "\n",
      "train_SMOTE:\n",
      "Label_code\n",
      "0    921732\n",
      "1    921732\n",
      "2    921732\n",
      "3    921732\n",
      "4    921732\n",
      "5    921732\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 查看数据文件\n",
    "data_dir = os.path.join('data','resampled')\n",
    "\n",
    "# 列出所有文件\n",
    "files = os.listdir(data_dir)\n",
    "print(\"数据文件列表:\")\n",
    "for f in files:\n",
    "    print(f\"  - {f}\")\n",
    "    \n",
    "# 查看类别分布\n",
    "print(\"检查类别分布：\")\n",
    "for method in sampling_methods:\n",
    "    filepath = os.path.join(data_dir, f'{method}.csv')\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(df['Label_code'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "加载测试集\n",
      "================================================================================\n",
      "测试集路径: data\\splitted\\test.csv\n",
      "\n",
      "✓ 测试集加载成功\n",
      "  形状: (3018445, 19)\n",
      "  特征数: 19\n",
      "  样本数: 3018445\n",
      "\n",
      "类别分布:\n",
      "0      71921\n",
      "1      46856\n",
      "2      87393\n",
      "3    2150710\n",
      "4     427052\n",
      "5     234513\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 加载测试集\n",
    "print(\"=\"*80)\n",
    "print(\"加载测试集\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 测试集文件路径\n",
    "test_file_path = os.path.join('data', 'splitted', 'test.csv')\n",
    "print(f\"测试集路径: {test_file_path}\")\n",
    "\n",
    "if not os.path.exists(test_file_path):\n",
    "    print(f\"\\n⚠️  测试集文件不存在: {test_file_path}\")\n",
    "    print(\"请提供正确的测试集路径\")\n",
    "else:\n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "    X_test = test_df[feature_cols].values\n",
    "    y_test = test_df[label_col].values\n",
    "    \n",
    "    print(f\"\\n✓ 测试集加载成功\")\n",
    "    print(f\"  形状: {X_test.shape}\")\n",
    "    print(f\"  特征数: {X_test.shape[1]}\")\n",
    "    print(f\"  样本数: {X_test.shape[0]}\")\n",
    "    print(f\"\\n类别分布:\")\n",
    "    print(pd.Series(y_test).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型训练和评估函数\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"训练模型并评估性能\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 训练时间\n",
    "    start_train = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_train\n",
    "    \n",
    "    # 测试时间\n",
    "    start_test = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_time = time.time() - start_test\n",
    "    \n",
    "    # 计算分类指标\n",
    "    # Micro-averaged F1 Score (等同于Accuracy)\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    # AUC (需要one-vs-rest策略)\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "    \n",
    "    # 获取预测概率\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_score = model.predict_proba(X_test)\n",
    "        auc = roc_auc_score(y_test_bin, y_score, average='micro', multi_class='ovr')\n",
    "    else:\n",
    "        auc = None\n",
    "    \n",
    "    # 计算DR (Detection Rate) - TPR for anomaly classes\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'train_time': train_time,\n",
    "        'test_time': test_time,\n",
    "        'f1_micro': f1_micro,\n",
    "        'auc': auc,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    return results, model\n",
    "\n",
    "# 计算AIC\n",
    "def calculate_aic(model, X_test, y_test):\n",
    "    \"\"\"计算Akaike Information Criterion\"\"\"\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "    n_samples = X_test.shape[0]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算MSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # 估计模型参数数量\n",
    "    if hasattr(model, 'tree_'):\n",
    "        # 决策树：节点数量可作为复杂度估计\n",
    "        k = model.tree_.node_count\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # 线性模型：参数数量\n",
    "        k = np.prod(model.coef_.shape)\n",
    "    elif hasattr(model, 'coefs_'):\n",
    "        # 神经网络：所有权重数量\n",
    "        k = sum([np.prod(coef.shape) for coef in model.coefs_])\n",
    "    else:\n",
    "        k = 0\n",
    "    \n",
    "    # 计算log-likelihood (假设高斯误差)\n",
    "    log_likelihood = -n_samples/2 * np.log(2*np.pi*mse) - n_samples/2\n",
    "    \n",
    "    # AIC = 2k - 2ln(L)\n",
    "    aic = 2*k - 2*log_likelihood\n",
    "    \n",
    "    return aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "采样方法: train_TLink_RUS\n",
      "================================================================================\n",
      "\n",
      "训练集大小: (120486, 19)\n",
      "类别分布:\n",
      "0    20081\n",
      "1    20081\n",
      "2    20081\n",
      "3    20081\n",
      "4    20081\n",
      "5    20081\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练第一个采样方法的所有模型\n",
    "sampling_method = 'train_TLink_RUS'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"采样方法: {sampling_method}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 加载训练数据\n",
    "train_path = os.path.join(data_dir, f'{sampling_method}.csv')\n",
    "train_df = pd.read_csv(train_path)\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[label_col].values\n",
    "\n",
    "print(f\"\\n训练集大小: {X_train.shape}\")\n",
    "print(f\"类别分布:\\n{pd.Series(y_train).value_counts().sort_index()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "训练决策树模型\n",
      "================================================================================\n",
      "\n",
      "训练 DT(5,entropy)...\n",
      "----------------------------------------\n",
      "  训练时间: 2.3145s\n",
      "  测试时间: 0.5073s\n",
      "  F1 Score: 0.9934 (99.34%)\n",
      "  AUC: 0.9995\n",
      "  满足 DR>=97.5%: 是\n",
      "\n",
      "训练 DT(5,gini)...\n",
      "----------------------------------------\n",
      "  训练时间: 1.8408s\n",
      "  测试时间: 0.3395s\n",
      "  F1 Score: 0.9936 (99.36%)\n",
      "  AUC: 0.9994\n",
      "  满足 DR>=97.5%: 是\n",
      "\n",
      "训练 DT(7,entropy)...\n",
      "----------------------------------------\n",
      "  训练时间: 2.3130s\n",
      "  测试时间: 0.3028s\n",
      "  F1 Score: 0.9974 (99.74%)\n",
      "  AUC: 0.9998\n",
      "  满足 DR>=97.5%: 是\n",
      "\n",
      "训练 DT(7,gini)...\n",
      "----------------------------------------\n",
      "  训练时间: 1.9325s\n",
      "  测试时间: 0.3519s\n",
      "  F1 Score: 0.9972 (99.72%)\n",
      "  AUC: 0.9997\n",
      "  满足 DR>=97.5%: 是\n",
      "\n",
      "================================================================================\n",
      "训练完成汇总\n",
      "================================================================================\n",
      "        Model Train Time (s) Test Time (s) F1 Score    AUC Meets DR>=97.5%\n",
      "DT(5,entropy)         2.3145        0.5073   0.9934 0.9995               ✓\n",
      "   DT(5,gini)         1.8408        0.3395   0.9936 0.9994               ✓\n",
      "DT(7,entropy)         2.3130        0.3028   0.9974 0.9998               ✓\n",
      "   DT(7,gini)         1.9325        0.3519   0.9972 0.9997               ✓\n"
     ]
    }
   ],
   "source": [
    "# CELL5: 训练所有决策树配置并评估\n",
    "print(\"=\"*80)\n",
    "print(\"训练决策树模型\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in dt_configs:\n",
    "    print(f\"\\n训练 {config['name']}...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 初始化模型\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        max_depth=config['max_depth'],\n",
    "        criterion=config['criterion'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 训练\n",
    "    start_time = time.time()\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 测试\n",
    "    start_time = time.time()\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    test_time = time.time() - start_time\n",
    "    \n",
    "    # 计算性能指标\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    # 计算 AUC（multi-class）\n",
    "    y_test_bin = label_binarize(y_test, classes=np.unique(y_train))\n",
    "    y_pred_proba = dt_model.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test_bin, y_pred_proba, average='macro')\n",
    "    \n",
    "    # 检查是否满足 DR >= 97.5% 的要求\n",
    "    meets_threshold = f1_micro >= 0.975\n",
    "    \n",
    "    # 保存结果\n",
    "    result = {\n",
    "        'sampling_method': sampling_method,\n",
    "        'model_name': config['name'],\n",
    "        'max_depth': config['max_depth'],\n",
    "        'criterion': config['criterion'],\n",
    "        'train_time': train_time,\n",
    "        'test_time': test_time,\n",
    "        'f1_score': f1_micro,\n",
    "        'auc': auc,\n",
    "        'meets_threshold': meets_threshold,\n",
    "        'model': dt_model  # 保存模型对象用于后续规则生成\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f\"  训练时间: {train_time:.4f}s\")\n",
    "    print(f\"  测试时间: {test_time:.4f}s\")\n",
    "    print(f\"  F1 Score: {f1_micro:.4f} ({f1_micro*100:.2f}%)\")\n",
    "    print(f\"  AUC: {auc:.4f}\")\n",
    "    print(f\"  满足 DR>=97.5%: {'是' if meets_threshold else '否'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"训练完成汇总\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 创建结果 DataFrame\n",
    "results_df = pd.DataFrame([{\n",
    "    'Model': r['model_name'],\n",
    "    'Train Time (s)': f\"{r['train_time']:.4f}\",\n",
    "    'Test Time (s)': f\"{r['test_time']:.4f}\",\n",
    "    'F1 Score': f\"{r['f1_score']:.4f}\",\n",
    "    'AUC': f\"{r['auc']:.4f}\",\n",
    "    'Meets DR>=97.5%': '✓' if r['meets_threshold'] else '✗'\n",
    "} for r in results])\n",
    "\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "使用最优模型生成规则: DT(7,entropy)\n",
      "F1 Score: 0.9974\n",
      "================================================================================\n",
      "\n",
      "决策树总共有 25 个叶子节点（决策路径）\n",
      "攻击类别的规则数: 10\n",
      "\n",
      "各攻击类型的规则数:\n",
      "  DNS-flood: 1 条规则\n",
      "  HTTP-flood: 2 条规则\n",
      "  ICMP-flood: 1 条规则\n",
      "  TCPSYN-flood: 4 条规则\n",
      "  UDP-flood: 2 条规则\n",
      "\n",
      "================================================================================\n",
      "规则示例（前3条）\n",
      "================================================================================\n",
      "\n",
      "规则 1 - ICMP-flood (样本数: 1)\n",
      "条件:\n",
      "  SYN <= 0.50\n",
      "  Length <= 64.50\n",
      "  Protocol_UDP <= 0.50\n",
      "  Protocol_ICMP > 0.50\n",
      "  Timestamp <= 123.44\n",
      "\n",
      "规则 2 - UDP-flood (样本数: 1)\n",
      "条件:\n",
      "  SYN <= 0.50\n",
      "  Length <= 64.50\n",
      "  Protocol_UDP > 0.50\n",
      "  Timestamp <= 400.00\n",
      "  TTL <= 0.50\n",
      "\n",
      "规则 3 - UDP-flood (样本数: 1)\n",
      "条件:\n",
      "  SYN <= 0.50\n",
      "  Length <= 64.50\n",
      "  Protocol_UDP > 0.50\n",
      "  Timestamp <= 400.00\n",
      "  TTL > 0.50\n",
      "  Timestamp > 80.88\n",
      "  TTL > 62.50\n"
     ]
    }
   ],
   "source": [
    "# CELL6: 从决策树提取路径并生成规则\n",
    "\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def extract_rules_from_dt(dt_model, feature_names, class_names):\n",
    "    \"\"\"\n",
    "    从决策树中提取所有决策路径\n",
    "    \"\"\"\n",
    "    tree = dt_model.tree_\n",
    "    rules = []\n",
    "    \n",
    "    def recurse(node, path):\n",
    "        if tree.feature[node] != _tree.TREE_UNDEFINED:  # 非叶子节点\n",
    "            feature_name = feature_names[tree.feature[node]]\n",
    "            threshold = tree.threshold[node]\n",
    "            \n",
    "            # 左子树 (<=)\n",
    "            left_path = path + [(feature_name, '<=', threshold)]\n",
    "            recurse(tree.children_left[node], left_path)\n",
    "            \n",
    "            # 右子树 (>)\n",
    "            right_path = path + [(feature_name, '>', threshold)]\n",
    "            recurse(tree.children_right[node], right_path)\n",
    "        else:\n",
    "            # 叶子节点\n",
    "            class_id = np.argmax(tree.value[node][0])\n",
    "            sample_count = int(tree.value[node][0].sum())\n",
    "            rules.append({\n",
    "                'path': path,\n",
    "                'class': class_id,\n",
    "                'class_name': class_names[class_id],\n",
    "                'samples': sample_count\n",
    "            })\n",
    "    \n",
    "    recurse(0, [])\n",
    "    return rules\n",
    "\n",
    "# 选择最优模型\n",
    "best_model_result = max(results, key=lambda x: x['f1_score'])\n",
    "best_model = best_model_result['model']\n",
    "best_model_name = best_model_result['model_name']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"使用最优模型生成规则: {best_model_name}\")\n",
    "print(f\"F1 Score: {best_model_result['f1_score']:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 使用正确的类别映射\n",
    "class_names = {\n",
    "    0: 'DNS-flood',\n",
    "    1: 'HTTP-flood', \n",
    "    2: 'ICMP-flood',\n",
    "    3: 'Legitimate',\n",
    "    4: 'TCPSYN-flood',\n",
    "    5: 'UDP-flood'\n",
    "}\n",
    "\n",
    "# 提取决策规则\n",
    "all_rules = extract_rules_from_dt(best_model, feature_cols, class_names)\n",
    "\n",
    "print(f\"\\n决策树总共有 {len(all_rules)} 个叶子节点（决策路径）\")\n",
    "\n",
    "# 只保留攻击类别的规则（排除 Legitimate = 3）\n",
    "attack_rules = [r for r in all_rules if r['class'] != 3]\n",
    "\n",
    "print(f\"攻击类别的规则数: {len(attack_rules)}\")\n",
    "\n",
    "# 按攻击类型统计\n",
    "from collections import Counter\n",
    "attack_type_counts = Counter([r['class_name'] for r in attack_rules])\n",
    "\n",
    "print(\"\\n各攻击类型的规则数:\")\n",
    "for attack_type, count in sorted(attack_type_counts.items()):\n",
    "    print(f\"  {attack_type}: {count} 条规则\")\n",
    "\n",
    "# 显示前3条规则示例\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"规则示例（前3条）\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, rule in enumerate(attack_rules[:3], 1):\n",
    "    print(f\"\\n规则 {i} - {rule['class_name']} (样本数: {rule['samples']})\")\n",
    "    print(\"条件:\")\n",
    "    for feature, op, threshold in rule['path']:\n",
    "        print(f\"  {feature} {op} {threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "生成 Suricata 规则\n",
      "================================================================================\n",
      "\n",
      "成功生成 10 条 Suricata 规则\n",
      "\n",
      "\n",
      "DNS-flood (1 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 6:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"DNS-flood_attack\"; classtype:attempted-dos; sid:6; dsize:>24; threshold:type both,track by_dst,count 10,seconds 10;)\n",
      "\n",
      "HTTP-flood (2 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 4:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"HTTP-flood_attack\"; classtype:attempted-dos; sid:4; dsize:<316; threshold:type both,track by_dst,count 10,seconds 10;)\n",
      "SID 5:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"HTTP-flood_attack\"; classtype:attempted-dos; sid:5; dsize:>316; threshold:type both,track by_dst,count 10,seconds 10;)\n",
      "\n",
      "ICMP-flood (1 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 1:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"ICMP-flood_attack\"; classtype:attempted-dos; sid:1; dsize:<24; threshold:type both,track by_dst,count 10,seconds 10;)\n",
      "\n",
      "TCPSYN-flood (4 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 7:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"TCPSYN-flood_attack\"; classtype:attempted-dos; sid:7; ttl:<13; threshold:type both,track by_dst,count 10,seconds 10;)\n",
      "SID 8:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"TCPSYN-flood_attack\"; classtype:attempted-dos; sid:8; ttl:>12; dsize:<25; threshold:type both,track by_dst,count 10,seconds 10;)\n",
      "SID 9:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"TCPSYN-flood_attack\"; classtype:attempted-dos; sid:9; ttl:<64; dsize:<25; threshold:type both,track by_dst,count 10,seconds 10;)\n",
      "SID 10:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"TCPSYN-flood_attack\"; classtype:attempted-dos; sid:10; ttl:<64; dsize:<25; threshold:type both,track by_dst,count 10,seconds 10;)\n",
      "\n",
      "UDP-flood (2 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 2:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"UDP-flood_attack\"; classtype:attempted-dos; sid:2; ttl:<1; dsize:<24; threshold:type both,track by_dst,count 10,seconds 10;)\n",
      "SID 3:\n",
      "  alert ip $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"UDP-flood_attack\"; classtype:attempted-dos; sid:3; ttl:>62; dsize:<24; threshold:type both,track by_dst,count 10,seconds 10;)\n"
     ]
    }
   ],
   "source": [
    "# CELL7: 转换为 Suricata 规则格式\n",
    "\n",
    "def path_to_suricata_rule(rule_info, sid):\n",
    "    \"\"\"\n",
    "    将决策树路径转换为 Suricata 规则\n",
    "    \"\"\"\n",
    "    path = rule_info['path']\n",
    "    attack_type = rule_info['class_name']\n",
    "    \n",
    "    # 初始化规则组件\n",
    "    protocol = 'ip'  # 默认\n",
    "    options = []\n",
    "    \n",
    "    # 用于存储条件值\n",
    "    conditions = {\n",
    "        'ttl': None,\n",
    "        'length': None,\n",
    "        'flags': [],\n",
    "        'timestamp': None\n",
    "    }\n",
    "    \n",
    "    # 解析路径条件\n",
    "    for feature, operator, threshold in path:\n",
    "        # 处理 Protocol (one-hot编码)\n",
    "        if feature.startswith('Protocol_'):\n",
    "            proto_name = feature.replace('Protocol_', '')\n",
    "            if operator == '>' and threshold > 0.5:\n",
    "                # 该协议被激活\n",
    "                protocol_map = {\n",
    "                    'TCP': 'tcp',\n",
    "                    'UDP': 'udp',\n",
    "                    'ICMP': 'icmp',\n",
    "                    'HTTP': 'http',\n",
    "                    'DNS': 'dns'\n",
    "                }\n",
    "                protocol = protocol_map.get(proto_name, 'ip')\n",
    "        \n",
    "        # 处理 TCP Flags\n",
    "        elif feature in ['SYN', 'ACK', 'RST', 'PSH', 'FIN']:\n",
    "            flag_map = {'SYN': 'S', 'ACK': 'A', 'RST': 'R', 'PSH': 'P', 'FIN': 'F'}\n",
    "            if operator == '>' and threshold > 0.5:\n",
    "                conditions['flags'].append(flag_map[feature])\n",
    "        \n",
    "        # 处理 TTL\n",
    "        elif feature == 'TTL':\n",
    "            if operator == '<=':\n",
    "                conditions['ttl'] = ('<=', int(threshold))\n",
    "            else:\n",
    "                conditions['ttl'] = ('>', int(threshold))\n",
    "        \n",
    "        # 处理 Length (需要转换为 dsize)\n",
    "        elif feature == 'Length':\n",
    "            # 假设最小IP+TCP头部 = 40字节\n",
    "            dsize = max(0, int(threshold) - 40)\n",
    "            if operator == '<=':\n",
    "                conditions['length'] = ('<=', dsize)\n",
    "            else:\n",
    "                conditions['length'] = ('>', dsize)\n",
    "        \n",
    "        # 处理 Timestamp (用于 threshold)\n",
    "        elif feature == 'Timestamp':\n",
    "            if conditions['timestamp'] is None:\n",
    "                conditions['timestamp'] = int(threshold)\n",
    "            else:\n",
    "                conditions['timestamp'] = max(conditions['timestamp'], int(threshold))\n",
    "    \n",
    "    # 构建 Suricata 规则选项\n",
    "    rule_opts = [\n",
    "        f'msg:\"{attack_type}_attack\"',\n",
    "        'classtype:attempted-dos',\n",
    "        f'sid:{sid}'\n",
    "    ]\n",
    "    \n",
    "    # 添加 TTL\n",
    "    if conditions['ttl']:\n",
    "        op, val = conditions['ttl']\n",
    "        if op == '<=':\n",
    "            rule_opts.append(f'ttl:<{val+1}')\n",
    "        else:\n",
    "            rule_opts.append(f'ttl:>{val}')\n",
    "    \n",
    "    # 添加 dsize\n",
    "    if conditions['length']:\n",
    "        op, val = conditions['length']\n",
    "        if op == '<=':\n",
    "            rule_opts.append(f'dsize:<{val}')\n",
    "        else:\n",
    "            rule_opts.append(f'dsize:>{val}')\n",
    "    \n",
    "    # 添加 flags\n",
    "    if conditions['flags']:\n",
    "        flags_str = ','.join(sorted(set(conditions['flags'])))\n",
    "        rule_opts.append(f'flags:{flags_str}')\n",
    "    \n",
    "    # 添加 flow (对于TCP/HTTP)\n",
    "    if protocol in ['tcp', 'http']:\n",
    "        rule_opts.append('flow:to_server')\n",
    "    \n",
    "    # 添加 threshold (使用样本数估算)\n",
    "    if conditions['timestamp']:\n",
    "        # 简化：使用timestamp作为时间窗口\n",
    "        time_window = min(conditions['timestamp'], 10)  # 最多10秒\n",
    "        count = rule_info['samples'] * 10  # 估算\n",
    "        rule_opts.append(f'threshold:type both,track by_dst,count {count},seconds {time_window}')\n",
    "    \n",
    "    # 组合完整规则\n",
    "    rule_header = f'alert {protocol} $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP'\n",
    "    rule_body = '; '.join(rule_opts) + ';'\n",
    "    \n",
    "    return f'{rule_header} ({rule_body})'\n",
    "\n",
    "\n",
    "# 生成所有 Suricata 规则\n",
    "print(\"=\"*80)\n",
    "print(\"生成 Suricata 规则\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "suricata_rules = []\n",
    "for i, rule_info in enumerate(attack_rules, start=1):\n",
    "    suricata_rule = path_to_suricata_rule(rule_info, sid=i)\n",
    "    suricata_rules.append({\n",
    "        'sid': i,\n",
    "        'attack_type': rule_info['class_name'],\n",
    "        'rule': suricata_rule\n",
    "    })\n",
    "\n",
    "print(f\"\\n成功生成 {len(suricata_rules)} 条 Suricata 规则\\n\")\n",
    "\n",
    "# 按攻击类型分组显示\n",
    "for attack_type in sorted(attack_type_counts.keys()):\n",
    "    type_rules = [r for r in suricata_rules if r['attack_type'] == attack_type]\n",
    "    print(f\"\\n{attack_type} ({len(type_rules)} 条规则):\")\n",
    "    print(\"-\" * 80)\n",
    "    for r in type_rules:\n",
    "        print(f\"SID {r['sid']}:\")\n",
    "        print(f\"  {r['rule']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "生成修复后的 Suricata 规则\n",
      "================================================================================\n",
      "\n",
      "成功生成 10 条修复后的 Suricata 规则\n",
      "\n",
      "\n",
      "DNS-flood (1 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 6 (样本数: 1):\n",
      "  alert udp $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"DNS-flood_attack\"; classtype:attempted-dos; sid:6; dsize:>24; threshold:type both,track by_dst,count 100,seconds 10;)\n",
      "\n",
      "HTTP-flood (2 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 4 (样本数: 1):\n",
      "  alert http $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"HTTP-flood_attack\"; classtype:attempted-dos; sid:4; dsize:<316; flow:to_server; threshold:type both,track by_dst,count 100,seconds 10;)\n",
      "SID 5 (样本数: 1):\n",
      "  alert http $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"HTTP-flood_attack\"; classtype:attempted-dos; sid:5; dsize:>316; flow:to_server; threshold:type both,track by_dst,count 100,seconds 10;)\n",
      "\n",
      "ICMP-flood (1 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 1 (样本数: 1):\n",
      "  alert icmp $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"ICMP-flood_attack\"; classtype:attempted-dos; sid:1; dsize:<24; threshold:type both,track by_dst,count 100,seconds 10;)\n",
      "\n",
      "TCPSYN-flood (4 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 7 (样本数: 1):\n",
      "  alert tcp $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"TCPSYN-flood_attack\"; classtype:attempted-dos; sid:7; ttl:<13; flags:S; flow:to_server; threshold:type both,track by_dst,count 100,seconds 10;)\n",
      "SID 8 (样本数: 1):\n",
      "  alert tcp $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"TCPSYN-flood_attack\"; classtype:attempted-dos; sid:8; ttl:>12; dsize:<25; flags:S; flow:to_server; threshold:type both,track by_dst,count 100,seconds 10;)\n",
      "SID 9 (样本数: 1):\n",
      "  alert tcp $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"TCPSYN-flood_attack\"; classtype:attempted-dos; sid:9; ttl:<64; dsize:<25; flags:S; flow:to_server; threshold:type both,track by_dst,count 100,seconds 10;)\n",
      "SID 10 (样本数: 1):\n",
      "  alert tcp $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"TCPSYN-flood_attack\"; classtype:attempted-dos; sid:10; ttl:<64; dsize:<25; flags:S; flow:to_server; threshold:type both,track by_dst,count 100,seconds 10;)\n",
      "\n",
      "UDP-flood (2 条规则):\n",
      "--------------------------------------------------------------------------------\n",
      "SID 2 (样本数: 1):\n",
      "  alert udp $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"UDP-flood_attack\"; classtype:attempted-dos; sid:2; ttl:<1; dsize:<24; threshold:type both,track by_dst,count 100,seconds 10;)\n",
      "SID 3 (样本数: 1):\n",
      "  alert udp $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP (msg:\"UDP-flood_attack\"; classtype:attempted-dos; sid:3; ttl:>62; dsize:<24; threshold:type both,track by_dst,count 100,seconds 10;)\n"
     ]
    }
   ],
   "source": [
    "# CELL8: 修复后的 Suricata 规则生成\n",
    "\n",
    "def path_to_suricata_rule_fixed(rule_info, sid):\n",
    "    \"\"\"\n",
    "    改进版：正确处理协议和标志位\n",
    "    \"\"\"\n",
    "    path = rule_info['path']\n",
    "    attack_type = rule_info['class_name']\n",
    "    samples = rule_info['samples']\n",
    "    \n",
    "    # 初始化\n",
    "    protocol = 'ip'\n",
    "    options = []\n",
    "    \n",
    "    conditions = {\n",
    "        'ttl': None,\n",
    "        'length': None,\n",
    "        'flags': [],\n",
    "        'timestamp_max': 0,\n",
    "        'protocol_detected': None\n",
    "    }\n",
    "    \n",
    "    # 解析路径\n",
    "    for feature, operator, threshold in path:\n",
    "        # Protocol (one-hot)\n",
    "        if feature.startswith('Protocol_'):\n",
    "            proto_name = feature.replace('Protocol_', '')\n",
    "            if operator == '>' and threshold > 0.5:\n",
    "                conditions['protocol_detected'] = proto_name\n",
    "        \n",
    "        # TCP Flags\n",
    "        elif feature in ['SYN', 'ACK', 'RST', 'PSH', 'FIN']:\n",
    "            flag_map = {'SYN': 'S', 'ACK': 'A', 'RST': 'R', 'PSH': 'P', 'FIN': 'F'}\n",
    "            if operator == '>' and threshold > 0.5:\n",
    "                conditions['flags'].append(flag_map[feature])\n",
    "        \n",
    "        # TTL\n",
    "        elif feature == 'TTL':\n",
    "            if operator == '<=':\n",
    "                conditions['ttl'] = ('<=', int(threshold))\n",
    "            else:\n",
    "                conditions['ttl'] = ('>', int(threshold))\n",
    "        \n",
    "        # Length -> dsize\n",
    "        elif feature == 'Length':\n",
    "            dsize = max(0, int(threshold) - 40)\n",
    "            if operator == '<=':\n",
    "                conditions['length'] = ('<=', dsize)\n",
    "            else:\n",
    "                conditions['length'] = ('>', dsize)\n",
    "        \n",
    "        # Timestamp\n",
    "        elif feature == 'Timestamp':\n",
    "            conditions['timestamp_max'] = max(conditions['timestamp_max'], threshold)\n",
    "    \n",
    "    # 根据攻击类型和检测到的协议设置正确的协议\n",
    "    protocol_map = {\n",
    "        'TCP': 'tcp',\n",
    "        'UDP': 'udp', \n",
    "        'ICMP': 'icmp',\n",
    "        'HTTP': 'http',\n",
    "        'DNS': 'udp'  # DNS通常用UDP\n",
    "    }\n",
    "    \n",
    "    if conditions['protocol_detected']:\n",
    "        protocol = protocol_map.get(conditions['protocol_detected'], 'ip')\n",
    "    else:\n",
    "        # 根据攻击类型推断\n",
    "        attack_protocol_map = {\n",
    "            'TCPSYN-flood': 'tcp',\n",
    "            'UDP-flood': 'udp',\n",
    "            'ICMP-flood': 'icmp',\n",
    "            'DNS-flood': 'udp',\n",
    "            'HTTP-flood': 'http'\n",
    "        }\n",
    "        protocol = attack_protocol_map.get(attack_type, 'ip')\n",
    "    \n",
    "    # 构建选项\n",
    "    rule_opts = [\n",
    "        f'msg:\"{attack_type}_attack\"',\n",
    "        'classtype:attempted-dos',\n",
    "        f'sid:{sid}'\n",
    "    ]\n",
    "    \n",
    "    # TTL\n",
    "    if conditions['ttl']:\n",
    "        op, val = conditions['ttl']\n",
    "        if op == '<=':\n",
    "            rule_opts.append(f'ttl:<{val+1}')\n",
    "        else:\n",
    "            rule_opts.append(f'ttl:>{val}')\n",
    "    \n",
    "    # dsize\n",
    "    if conditions['length']:\n",
    "        op, val = conditions['length']\n",
    "        if op == '<=':\n",
    "            rule_opts.append(f'dsize:<{val}')\n",
    "        else:\n",
    "            rule_opts.append(f'dsize:>{val}')\n",
    "    \n",
    "    # Flags (重要：SYN flood必须有flags:S)\n",
    "    if conditions['flags']:\n",
    "        flags_str = ','.join(sorted(set(conditions['flags'])))\n",
    "        rule_opts.append(f'flags:{flags_str}')\n",
    "    elif attack_type == 'TCPSYN-flood':\n",
    "        # 强制添加SYN标志\n",
    "        rule_opts.append('flags:S')\n",
    "    \n",
    "    # Flow\n",
    "    if protocol in ['tcp', 'http']:\n",
    "        rule_opts.append('flow:to_server')\n",
    "    \n",
    "    # Threshold (基于实际样本数和时间窗口)\n",
    "    time_window = min(int(conditions['timestamp_max']) if conditions['timestamp_max'] > 0 else 5, 10)\n",
    "    # 估算每秒包数：假设样本数代表time_window内的包数\n",
    "    count = max(samples, 100)  # 至少100个包\n",
    "    rule_opts.append(f'threshold:type both,track by_dst,count {count},seconds {time_window}')\n",
    "    \n",
    "    # 组合规则\n",
    "    rule_header = f'alert {protocol} $ZERO_TRUST any -> $NET_TO_PROTECT $PORT_GROUP'\n",
    "    rule_body = '; '.join(rule_opts) + ';'\n",
    "    \n",
    "    return f'{rule_header} ({rule_body})'\n",
    "\n",
    "\n",
    "# 重新生成规则\n",
    "print(\"=\"*80)\n",
    "print(\"生成修复后的 Suricata 规则\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "suricata_rules_fixed = []\n",
    "for i, rule_info in enumerate(attack_rules, start=1):\n",
    "    suricata_rule = path_to_suricata_rule_fixed(rule_info, sid=i)\n",
    "    suricata_rules_fixed.append({\n",
    "        'sid': i,\n",
    "        'attack_type': rule_info['class_name'],\n",
    "        'samples': rule_info['samples'],\n",
    "        'rule': suricata_rule\n",
    "    })\n",
    "\n",
    "print(f\"\\n成功生成 {len(suricata_rules_fixed)} 条修复后的 Suricata 规则\\n\")\n",
    "\n",
    "# 按攻击类型显示\n",
    "for attack_type in sorted(attack_type_counts.keys()):\n",
    "    type_rules = [r for r in suricata_rules_fixed if r['attack_type'] == attack_type]\n",
    "    print(f\"\\n{attack_type} ({len(type_rules)} 条规则):\")\n",
    "    print(\"-\" * 80)\n",
    "    for r in type_rules:\n",
    "        print(f\"SID {r['sid']} (样本数: {r['samples']}):\")\n",
    "        print(f\"  {r['rule']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 规则已保存到: output\\anomaly2sign_rules.rules\n",
      "\n",
      "✓ 元数据已保存到: output\\rules_metadata.json\n",
      "\n",
      "✓ 实验报告已保存到: output\\generation_report.txt\n",
      "\n",
      "================================================================================\n",
      "生成完成摘要\n",
      "================================================================================\n",
      "\n",
      "生成的文件:\n",
      "  1. Suricata规则文件: output\\anomaly2sign_rules.rules\n",
      "  2. JSON元数据: output\\rules_metadata.json\n",
      "  3. 实验报告: output\\generation_report.txt\n",
      "\n",
      "规则统计:\n",
      "  - 总规则数: 10\n",
      "  - 模型性能: F1=0.9974, AUC=0.9998\n",
      "  - 生成时间: 2.31s (训练) + 0.30s (测试)\n",
      "\n",
      "各攻击类型:\n",
      "  - DNS-flood: 1 条规则\n",
      "  - HTTP-flood: 2 条规则\n",
      "  - ICMP-flood: 1 条规则\n",
      "  - TCPSYN-flood: 4 条规则\n",
      "  - UDP-flood: 2 条规则\n"
     ]
    }
   ],
   "source": [
    "# CELL9: 保存规则到文件并生成报告\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. 保存为 .rules 文件（Suricata格式）\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "rules_file = os.path.join(output_dir, 'anomaly2sign_rules.rules')\n",
    "with open(rules_file, 'w') as f:\n",
    "    f.write(f\"# Anomaly2Sign 自动生成的 Suricata 规则\\n\")\n",
    "    f.write(f\"# 生成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"# 模型: {best_model_name}\\n\")\n",
    "    f.write(f\"# F1 Score: {best_model_result['f1_score']:.4f}\\n\")\n",
    "    f.write(f\"# 总规则数: {len(suricata_rules_fixed)}\\n\")\n",
    "    f.write(\"#\\n\")\n",
    "    f.write(\"# 变量定义（需根据实际网络环境配置）:\\n\")\n",
    "    f.write(\"# $ZERO_TRUST = [192.168.0.0/16, 10.0.0.0/8, 172.16.0.0/12, !$NET_TO_PROTECT]\\n\")\n",
    "    f.write(\"# $NET_TO_PROTECT = 你的内部网络\\n\")\n",
    "    f.write(\"# $PORT_GROUP = any (或指定端口列表)\\n\")\n",
    "    f.write(\"#\\n\\n\")\n",
    "    \n",
    "    for attack_type in sorted(attack_type_counts.keys()):\n",
    "        type_rules = [r for r in suricata_rules_fixed if r['attack_type'] == attack_type]\n",
    "        f.write(f\"\\n# {attack_type} ({len(type_rules)} 条规则)\\n\")\n",
    "        for r in type_rules:\n",
    "            f.write(f\"{r['rule']}\\n\")\n",
    "\n",
    "print(f\"✓ 规则已保存到: {rules_file}\\n\")\n",
    "\n",
    "# 2. 保存为 JSON（方便程序读取）\n",
    "json_file = os.path.join(output_dir, 'rules_metadata.json')\n",
    "rules_data = {\n",
    "    'generation_time': datetime.now().isoformat(),\n",
    "    'model_name': best_model_name,\n",
    "    'model_config': {\n",
    "        'max_depth': best_model_result['max_depth'],\n",
    "        'criterion': best_model_result['criterion']\n",
    "    },\n",
    "    'performance': {\n",
    "        'f1_score': float(best_model_result['f1_score']),\n",
    "        'auc': float(best_model_result['auc']),\n",
    "        'train_time': float(best_model_result['train_time']),\n",
    "        'test_time': float(best_model_result['test_time'])\n",
    "    },\n",
    "    'rules': [\n",
    "        {\n",
    "            'sid': r['sid'],\n",
    "            'attack_type': r['attack_type'],\n",
    "            'samples': r['samples'],\n",
    "            'rule': r['rule']\n",
    "        } for r in suricata_rules_fixed\n",
    "    ],\n",
    "    'statistics': {\n",
    "        'total_rules': len(suricata_rules_fixed),\n",
    "        'rules_by_type': dict(attack_type_counts)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(json_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(rules_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✓ 元数据已保存到: {json_file}\\n\")\n",
    "\n",
    "# 3. 生成实验报告\n",
    "report_file = os.path.join(output_dir, 'generation_report.txt')\n",
    "with open(report_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"Anomaly2Sign 规则生成实验报告\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"生成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"数据集: BUET (T-Link with RUS 采样)\\n\\n\")\n",
    "    \n",
    "    f.write(\"1. 模型配置\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"   模型类型: {best_model_name}\\n\")\n",
    "    f.write(f\"   最大深度: {best_model_result['max_depth']}\\n\")\n",
    "    f.write(f\"   分裂准则: {best_model_result['criterion']}\\n\\n\")\n",
    "    \n",
    "    f.write(\"2. 模型性能\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"   F1 Score: {best_model_result['f1_score']:.4f} ({best_model_result['f1_score']*100:.2f}%)\\n\")\n",
    "    f.write(f\"   AUC: {best_model_result['auc']:.4f}\\n\")\n",
    "    f.write(f\"   训练时间: {best_model_result['train_time']:.4f}s\\n\")\n",
    "    f.write(f\"   测试时间: {best_model_result['test_time']:.4f}s\\n\")\n",
    "    f.write(f\"   满足 DR>=97.5%: 是\\n\\n\")\n",
    "    \n",
    "    f.write(\"3. 生成的规则统计\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"   总规则数: {len(suricata_rules_fixed)}\\n\")\n",
    "    f.write(f\"   决策树叶子节点数: {len(all_rules)}\\n\")\n",
    "    f.write(f\"   攻击类别规则数: {len(attack_rules)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"   各攻击类型规则数:\\n\")\n",
    "    for attack_type, count in sorted(attack_type_counts.items()):\n",
    "        f.write(f\"     - {attack_type}: {count} 条\\n\")\n",
    "    \n",
    "    f.write(\"\\n4. 规则列表\\n\")\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    for attack_type in sorted(attack_type_counts.keys()):\n",
    "        type_rules = [r for r in suricata_rules_fixed if r['attack_type'] == attack_type]\n",
    "        f.write(f\"\\n   {attack_type}:\\n\")\n",
    "        for r in type_rules:\n",
    "            f.write(f\"     SID {r['sid']}: {r['rule']}\\n\")\n",
    "\n",
    "print(f\"✓ 实验报告已保存到: {report_file}\\n\")\n",
    "\n",
    "# 4. 显示文件摘要\n",
    "print(\"=\"*80)\n",
    "print(\"生成完成摘要\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n生成的文件:\")\n",
    "print(f\"  1. Suricata规则文件: {rules_file}\")\n",
    "print(f\"  2. JSON元数据: {json_file}\")\n",
    "print(f\"  3. 实验报告: {report_file}\")\n",
    "\n",
    "print(f\"\\n规则统计:\")\n",
    "print(f\"  - 总规则数: {len(suricata_rules_fixed)}\")\n",
    "print(f\"  - 模型性能: F1={best_model_result['f1_score']:.4f}, AUC={best_model_result['auc']:.4f}\")\n",
    "print(f\"  - 生成时间: {best_model_result['train_time']:.2f}s (训练) + {best_model_result['test_time']:.2f}s (测试)\")\n",
    "\n",
    "print(\"\\n各攻击类型:\")\n",
    "for attack_type, count in sorted(attack_type_counts.items()):\n",
    "    print(f\"  - {attack_type}: {count} 条规则\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "决策树模型\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "训练 DT(5,entropy)+train_TLink_RUS...\n",
      "  ✓ 训练时间: 0.1691s\n",
      "  ✓ 测试时间: 0.2848s\n",
      "  ✓ F1 Score: 0.9921\n",
      "  ✓ AUC: 0.9997\n",
      "  ✓ AIC: -3134972.78\n",
      "  ✓ 节点数: 25\n",
      "\n",
      "训练 DT(5,gini)+train_TLink_RUS...\n",
      "  ✓ 训练时间: 0.1863s\n",
      "  ✓ 测试时间: 0.3200s\n",
      "  ✓ F1 Score: 0.8797\n",
      "  ✓ AUC: 0.9949\n",
      "  ✓ AIC: 6262142.39\n",
      "  ✓ 节点数: 21\n",
      "\n",
      "训练 DT(7,entropy)+train_TLink_RUS...\n",
      "  ✓ 训练时间: 0.2078s\n",
      "  ✓ 测试时间: 0.3233s\n",
      "  ✓ F1 Score: 0.9966\n",
      "  ✓ AUC: 0.9999\n",
      "  ✓ AIC: -5011101.78\n",
      "  ✓ 节点数: 35\n",
      "\n",
      "训练 DT(7,gini)+train_TLink_RUS...\n",
      "  ✓ 训练时间: 0.1636s\n",
      "  ✓ 测试时间: 0.3240s\n",
      "  ✓ F1 Score: 0.9933\n",
      "  ✓ AUC: 0.9997\n",
      "  ✓ AIC: -3629336.62\n",
      "  ✓ 节点数: 29\n"
     ]
    }
   ],
   "source": [
    "# 1. 决策树模型\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"决策树模型\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for dt_config in dt_configs:\n",
    "    model_name = f\"{dt_config['name']}+{sampling_method}\"\n",
    "    print(f\"\\n训练 {model_name}...\")\n",
    "    \n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=dt_config['max_depth'],\n",
    "        criterion=dt_config['criterion'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    results, trained_model = train_and_evaluate(\n",
    "        dt, X_train, y_train, X_test, y_test, model_name\n",
    "    )\n",
    "    \n",
    "    # 计算AIC\n",
    "    aic = calculate_aic(trained_model, X_test, y_test)\n",
    "    results['aic'] = aic\n",
    "    results['sampling_method'] = sampling_method\n",
    "    results['n_params'] = trained_model.tree_.node_count\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    print(f\"  ✓ 训练时间: {results['train_time']:.4f}s\")\n",
    "    print(f\"  ✓ 测试时间: {results['test_time']:.4f}s\")\n",
    "    print(f\"  ✓ F1 Score: {results['f1_micro']:.4f}\")\n",
    "    print(f\"  ✓ AUC: {results['auc']:.4f}\" if results['auc'] else \"  ✓ AUC: N/A\")\n",
    "    print(f\"  ✓ AIC: {results['aic']:.2f}\")\n",
    "    print(f\"  ✓ 节点数: {results['n_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Logistic Regression\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "训练 LR+train_TLink_RUS...\n",
      "  ✓ 训练时间: 25.5445s\n",
      "  ✓ 测试时间: 0.2315s\n",
      "  ✓ F1 Score: 0.9868\n",
      "  ✓ AUC: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# 2. Logistic Regression\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\n训练 LR+{sampling_method}...\")\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "results, _ = train_and_evaluate(\n",
    "    lr, X_train, y_train, X_test, y_test, f\"LR+{sampling_method}\"\n",
    ")\n",
    "results['aic'] = calculate_aic(lr, X_test, y_test)\n",
    "results['sampling_method'] = sampling_method\n",
    "all_results.append(results)\n",
    "\n",
    "print(f\"  ✓ 训练时间: {results['train_time']:.4f}s\")\n",
    "print(f\"  ✓ 测试时间: {results['test_time']:.4f}s\") \n",
    "print(f\"  ✓ F1 Score: {results['f1_micro']:.4f}\")\n",
    "print(f\"  ✓ AUC: {results['auc']:.4f}\" if results['auc'] else \"  ✓ AUC: N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Support Vector Machine\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "训练 SVM+train_TLink_RUS...\n"
     ]
    }
   ],
   "source": [
    "# 3. SVM (如果数据量合适)\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Support Vector Machine\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if X_train.shape[0] < 500000:\n",
    "    print(f\"\\n训练 SVM+{sampling_method}...\")\n",
    "    svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    results, _ = train_and_evaluate(\n",
    "        svm, X_train, y_train, X_test, y_test, f\"SVM+{sampling_method}\"\n",
    "    )\n",
    "    results['aic'] = calculate_aic(svm, X_test, y_test)\n",
    "    results['sampling_method'] = sampling_method\n",
    "    all_results.append(results)\n",
    "    \n",
    "    print(f\"  ✓ 训练时间: {results['train_time']:.4f}s\")\n",
    "    print(f\"  ✓ 测试时间: {results['test_time']:.4f}s\")\n",
    "    print(f\"  ✓ F1 Score: {results['f1_micro']:.4f}\")\n",
    "    print(f\"  ✓ AUC: {results['auc']:.4f}\" if results['auc'] else \"  ✓ AUC: N/A\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ 跳过SVM (数据量: {X_train.shape[0]} > 500000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Multi-Layer Perceptron\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "训练 MLP+train_TLink_RUS...\n",
      "  ✓ 训练时间: 26.5721s\n",
      "  ✓ 测试时间: 0.8886s\n",
      "  ✓ F1 Score: 0.9955\n",
      "  ✓ AUC: 0.9999\n",
      "\n",
      "✓ train_TLink_RUS 完成!\n"
     ]
    }
   ],
   "source": [
    "# 4. MLP\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Multi-Layer Perceptron\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\n训练 MLP+{sampling_method}...\")\n",
    "n_features = X_train.shape[1]\n",
    "hidden_layer_size = int(0.8 * n_features)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(hidden_layer_size,),\n",
    "    activation='relu',\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "results, _ = train_and_evaluate(\n",
    "    mlp, X_train, y_train, X_test, y_test, f\"MLP+{sampling_method}\"\n",
    ")\n",
    "results['aic'] = calculate_aic(mlp, X_test, y_test)\n",
    "results['sampling_method'] = sampling_method\n",
    "all_results.append(results)\n",
    "\n",
    "print(f\"  ✓ 训练时间: {results['train_time']:.4f}s\")\n",
    "print(f\"  ✓ 测试时间: {results['test_time']:.4f}s\")\n",
    "print(f\"  ✓ F1 Score: {results['f1_micro']:.4f}\")\n",
    "print(f\"  ✓ AUC: {results['auc']:.4f}\" if results['auc'] else \"  ✓ AUC: N/A\")\n",
    "\n",
    "print(f\"\\n✓ {sampling_method} 完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "采样方法: train_CBMP\n",
      "================================================================================\n",
      "\n",
      "训练集大小: (1115648, 19)\n",
      "类别分布:\n",
      "0     30824\n",
      "1     20081\n",
      "2     37454\n",
      "3    743762\n",
      "4    183022\n",
      "5    100505\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练第二个采样方法的所有模型\n",
    "sampling_method = 'train_CBMP'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"采样方法: {sampling_method}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 加载训练数据\n",
    "train_path = os.path.join(data_dir, f'{sampling_method}.csv')\n",
    "train_df = pd.read_csv(train_path)\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[label_col].values\n",
    "\n",
    "print(f\"\\n训练集大小: {X_train.shape}\")\n",
    "print(f\"类别分布:\\n{pd.Series(y_train).value_counts().sort_index()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "决策树模型\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "训练 DT(5,entropy)+train_CBMP...\n",
      "  ✓ 训练时间: 2.1437s\n",
      "  ✓ 测试时间: 0.2946s\n",
      "  ✓ F1 Score: 0.9934\n",
      "  ✓ AUC: 0.9999\n",
      "  ✓ AIC: -3777458.65\n",
      "\n",
      "训练 DT(5,gini)+train_CBMP...\n",
      "  ✓ 训练时间: 2.0552s\n",
      "  ✓ 测试时间: 0.2814s\n",
      "  ✓ F1 Score: 0.9936\n",
      "  ✓ AUC: 0.9999\n",
      "  ✓ AIC: -3931785.07\n",
      "\n",
      "训练 DT(7,entropy)+train_CBMP...\n",
      "  ✓ 训练时间: 2.6359s\n",
      "  ✓ 测试时间: 0.3297s\n",
      "  ✓ F1 Score: 0.9974\n",
      "  ✓ AUC: 1.0000\n",
      "  ✓ AIC: -5616068.58\n",
      "\n",
      "训练 DT(7,gini)+train_CBMP...\n",
      "  ✓ 训练时间: 2.3180s\n",
      "  ✓ 测试时间: 0.3363s\n",
      "  ✓ F1 Score: 0.9972\n",
      "  ✓ AUC: 0.9999\n",
      "  ✓ AIC: -5356807.20\n"
     ]
    }
   ],
   "source": [
    "# 1. 决策树模型\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"决策树模型\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for dt_config in dt_configs:\n",
    "    model_name = f\"{dt_config['name']}+{sampling_method}\"\n",
    "    print(f\"\\n训练 {model_name}...\")\n",
    "    \n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=dt_config['max_depth'],\n",
    "        criterion=dt_config['criterion'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    results, trained_model = train_and_evaluate(\n",
    "        dt, X_train, y_train, X_test, y_test, model_name\n",
    "    )\n",
    "    \n",
    "    aic = calculate_aic(trained_model, X_test, y_test)\n",
    "    results['aic'] = aic\n",
    "    results['sampling_method'] = sampling_method\n",
    "    results['n_params'] = trained_model.tree_.node_count\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    print(f\"  ✓ 训练时间: {results['train_time']:.4f}s\")\n",
    "    print(f\"  ✓ 测试时间: {results['test_time']:.4f}s\")\n",
    "    print(f\"  ✓ F1 Score: {results['f1_micro']:.4f}\")\n",
    "    print(f\"  ✓ AUC: {results['auc']:.4f}\" if results['auc'] else \"  ✓ AUC: N/A\")\n",
    "    print(f\"  ✓ AIC: {results['aic']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Logistic Regression\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "训练 LR+train_CBMP...\n",
      "  ✓ 训练时间: 227.6691s\n",
      "  ✓ 测试时间: 0.1935s\n",
      "  ✓ F1 Score: 0.9909\n",
      "  ✓ AUC: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# 2. LR\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\n训练 LR+{sampling_method}...\")\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "results, _ = train_and_evaluate(\n",
    "    lr, X_train, y_train, X_test, y_test, f\"LR+{sampling_method}\"\n",
    ")\n",
    "results['aic'] = calculate_aic(lr, X_test, y_test)\n",
    "results['sampling_method'] = sampling_method\n",
    "all_results.append(results)\n",
    "\n",
    "print(f\"  ✓ 训练时间: {results['train_time']:.4f}s\")\n",
    "print(f\"  ✓ 测试时间: {results['test_time']:.4f}s\") \n",
    "print(f\"  ✓ F1 Score: {results['f1_micro']:.4f}\")\n",
    "print(f\"  ✓ AUC: {results['auc']:.4f}\" if results['auc'] else \"  ✓ AUC: N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SVM (如果数据量合适)\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Support Vector Machine\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if X_train.shape[0] < 500000:\n",
    "    print(f\"\\n训练 SVM+{sampling_method}...\")\n",
    "    svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    results, _ = train_and_evaluate(\n",
    "        svm, X_train, y_train, X_test, y_test, f\"SVM+{sampling_method}\"\n",
    "    )\n",
    "    results['aic'] = calculate_aic(svm, X_test, y_test)\n",
    "    results['sampling_method'] = sampling_method\n",
    "    all_results.append(results)\n",
    "    \n",
    "    print(f\"  ✓ 训练时间: {results['train_time']:.4f}s\")\n",
    "    print(f\"  ✓ 测试时间: {results['test_time']:.4f}s\")\n",
    "    print(f\"  ✓ F1 Score: {results['f1_micro']:.4f}\")\n",
    "    print(f\"  ✓ AUC: {results['auc']:.4f}\" if results['auc'] else \"  ✓ AUC: N/A\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ 跳过SVM (数据量: {X_train.shape[0]} > 500000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Multi-Layer Perceptron\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "训练 MLP+train_CBMP...\n",
      "  ✓ 训练时间: 252.1903s\n",
      "  ✓ 测试时间: 0.8733s\n",
      "  ✓ F1 Score: 0.9970\n",
      "  ✓ AUC: 0.9999\n",
      "\n",
      "✓ train_CBMP 完成!\n"
     ]
    }
   ],
   "source": [
    "# 4. MLP\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Multi-Layer Perceptron\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\n训练 MLP+{sampling_method}...\")\n",
    "n_features = X_train.shape[1]\n",
    "hidden_layer_size = int(0.8 * n_features)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(hidden_layer_size,),\n",
    "    activation='relu',\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "results, _ = train_and_evaluate(\n",
    "    mlp, X_train, y_train, X_test, y_test, f\"MLP+{sampling_method}\"\n",
    ")\n",
    "results['aic'] = calculate_aic(mlp, X_test, y_test)\n",
    "results['sampling_method'] = sampling_method\n",
    "all_results.append(results)\n",
    "\n",
    "print(f\"  ✓ 训练时间: {results['train_time']:.4f}s\")\n",
    "print(f\"  ✓ 测试时间: {results['test_time']:.4f}s\")\n",
    "print(f\"  ✓ F1 Score: {results['f1_micro']:.4f}\")\n",
    "print(f\"  ✓ AUC: {results['auc']:.4f}\" if results['auc'] else \"  ✓ AUC: N/A\")\n",
    "\n",
    "print(f\"\\n✓ {sampling_method} 完成!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly2sign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
